{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f7d9761-e5be-4d11-b9b7-1db9e693d86b",
   "metadata": {},
   "source": [
    "## Optical Flow for Horizontal Rolling Text Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ab40b0-7796-48d2-899b-96383b296e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc4e5f-c5c2-4601-9a93-3229fec58220",
   "metadata": {},
   "source": [
    "#### To see optical flow refinement during the entire video (just for visualization)   \n",
    "Press 'q' to quit the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c25029f-70bf-464b-b255-b49433e42d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_horizontal_flow(img, flow, step=30):\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx = flow[y, x, 0]\n",
    "    fy = flow[y, x, 1]\n",
    "\n",
    "    # Keep only leftward motion vectors (negative horizontal flow)\n",
    "    fx[fx > 0] = 0\n",
    "\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.arrowedLine(vis, (x1, y1), (x2, y2), (0, 255, 0), 1, tipLength=0.5)\n",
    "    return vis\n",
    "\n",
    "def detect(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get total number of frames and calculate halfway point\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    halfway_frame = total_frames // 2\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video file.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize a mask for consistent leftward movement\n",
    "    consistent_motion_mask = None\n",
    "    consistency_threshold = 0.7  # Consistent movement threshold (percentage of frames)\n",
    "    num_frames = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 5, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Calculate the mask of leftward movement\n",
    "        leftward_motion_mask = flow[..., 0] < 0\n",
    "        \n",
    "        # Initialize the consistent motion mask\n",
    "        if consistent_motion_mask is None:\n",
    "            consistent_motion_mask = np.zeros_like(leftward_motion_mask, dtype=np.float32)\n",
    "        \n",
    "        # Update the consistent leftward movement mask\n",
    "        consistent_motion_mask[leftward_motion_mask] += 1\n",
    "        num_frames += 1\n",
    "\n",
    "        # Calculate the ratio of consistent leftward movement\n",
    "        consistent_ratio = consistent_motion_mask / num_frames\n",
    "        consistent_leftward_regions = consistent_ratio > consistency_threshold\n",
    "\n",
    "        # Apply morphological operations to fill in the gaps\n",
    "        consistent_leftward_mask = consistent_leftward_regions.astype(np.uint8)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        consistent_leftward_mask = cv2.morphologyEx(consistent_leftward_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Create an image for highlighting\n",
    "        consistent_leftward_img = np.zeros_like(frame)\n",
    "        consistent_leftward_img[consistent_leftward_mask == 1] = [0, 255, 0]  # Green\n",
    "\n",
    "        vis = draw_horizontal_flow(gray, flow)\n",
    "\n",
    "        # Combine visualization with consistent leftward movement highlight\n",
    "        combined_vis = cv2.addWeighted(vis, 0.7, consistent_leftward_img, 0.3, 0)\n",
    "        cv2.imshow('Horizontal Optical Flow', combined_vis)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = 'stationary.mp4'\n",
    "detect(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d53636-2d15-458f-82fe-b1ca131428db",
   "metadata": {},
   "source": [
    "#### We see that the refined optical flow view is best around halfway through the video, when there is enough motion information to be confident about consistent horizontal movement. Save a screengrab of the video with optical flow hilights at the halfway frame.  \n",
    "This won't display the video anymore. Still may take several seconds to run.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8b02e25-3216-4a73-8983-e72457011524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_horizontal_flow(img, flow, step=30):\n",
    "    \"\"\"Draw optical flow vectors on the video.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx = flow[y, x, 0]\n",
    "    fy = flow[y, x, 1]\n",
    "\n",
    "    # Keep only leftward motion vectors (negative horizontal flow)\n",
    "    fx[fx > 0] = 0\n",
    "\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.arrowedLine(vis, (x1, y1), (x2, y2), (0, 255, 0), 1, tipLength=0.5)\n",
    "    return vis\n",
    "\n",
    "def detect_and_save_screengrab(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get total number of frames and calculate halfway point\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    halfway_frame = total_frames // 2\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video file.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize a mask for consistent leftward movement\n",
    "    consistent_motion_mask = None\n",
    "    consistency_threshold = 0.8  # Consistent movement threshold (percentage of frames)\n",
    "    num_frames = 0\n",
    "\n",
    "    saved_screengrab = False\n",
    "    screengrab_frame = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 5, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Calculate the mask of leftward movement\n",
    "        leftward_motion_mask = flow[..., 0] < 0\n",
    "        \n",
    "        # Initialize the consistent motion mask\n",
    "        if consistent_motion_mask is None:\n",
    "            consistent_motion_mask = np.zeros_like(leftward_motion_mask, dtype=np.float32)\n",
    "        \n",
    "        # Update the consistent leftward movement mask\n",
    "        consistent_motion_mask[leftward_motion_mask] += 1\n",
    "        num_frames += 1\n",
    "\n",
    "        # Calculate the ratio of consistent leftward movement\n",
    "        consistent_ratio = consistent_motion_mask / num_frames\n",
    "        consistent_leftward_regions = consistent_ratio > consistency_threshold\n",
    "\n",
    "        # Apply morphological operations to fill in the gaps\n",
    "        consistent_leftward_mask = consistent_leftward_regions.astype(np.uint8)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        consistent_leftward_mask = cv2.morphologyEx(consistent_leftward_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Create an image for highlighting\n",
    "        consistent_leftward_img = np.zeros_like(frame)\n",
    "        consistent_leftward_img[consistent_leftward_mask == 1] = [0, 255, 0]  # Green\n",
    "\n",
    "        vis = draw_horizontal_flow(gray, flow)\n",
    "\n",
    "        # Combine visualization with consistent leftward movement highlight\n",
    "        combined_vis = cv2.addWeighted(vis, 0.7, consistent_leftward_img, 0.3, 0)\n",
    "\n",
    "        # Save screengrab at halfway point\n",
    "        if num_frames == halfway_frame and not saved_screengrab:\n",
    "            screengrab_frame = combined_vis.copy()\n",
    "            saved_screengrab = True\n",
    "        \n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    # Save the screengrab outside the loop to avoid delay\n",
    "    if screengrab_frame is not None:\n",
    "        vidname = str(video_path)\n",
    "        cv2.imwrite(f'{vidname}_screengrab_halfway.png', screengrab_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "########## CALL TO FUNCTION:\n",
    "vids_to_process = ['stationary.mp4']\n",
    "for vid in vids_to_process:\n",
    "    detect_and_save_screengrab(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f24c9-0d91-4ef2-be7d-47458dd6edc7",
   "metadata": {},
   "source": [
    "#### Draw a bounding box around the detected regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4af0b7c-f32a-4610-ac75-fdcd23c96a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_boxes(screengrab_path, height_increase):\n",
    "    screengrab = cv2.imread(screengrab_path)\n",
    "    if screengrab is None:\n",
    "        print(\"Failed to read the screengrab.\")\n",
    "        return\n",
    "\n",
    "    # Convert to HSV and create a mask for the green color\n",
    "    hsv = cv2.cvtColor(screengrab, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([40, 40, 40])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around significant motion regions\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 700:  # Adjust the threshold for minimum area as needed\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Increase the height of the bounding box\n",
    "            y = max(0, y - height_increase // 2)\n",
    "            h = h + height_increase\n",
    "            # Ensure the bounding box is within the image boundaries\n",
    "            h = min(h, screengrab.shape[0] - y)\n",
    "            cv2.rectangle(screengrab, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Save and display the image with bounding boxes\n",
    "    cv2.imwrite('screengrab_with_bounding_boxes.png', screengrab)\n",
    "\n",
    "########## CALL TO FUNCTION:\n",
    "for vid in ['stationary.mp4']:\n",
    "    extract_bounding_boxes(f'{vid}_screengrab_halfway.png', height_increase=0) # Add extra height to ensure no text is cut off from the top/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727f9743-acf2-440f-bb98-a1d97cbcfd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (HLCV-env)",
   "language": "python",
   "name": "myproject-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
