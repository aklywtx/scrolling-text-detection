{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can change some hyperparameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameter\n",
    "frame_interval = 25\n",
    "east_confidence = 0.5\n",
    "opflow_min_area_threshold = 700\n",
    "opflow_height_increase = 0\n",
    "num_frames_for_overlap_check = 3\n",
    "rolling_text_confidence = 0.2 # if the overlapping area / east box area > 0.2, this is a part of the rolling text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can change the video path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path\n",
    "vidpath = '../data/train4_crop.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files(vidpath):\n",
    "    base_name = os.path.basename(vidpath)\n",
    "    vidname, _ = os.path.splitext(base_name)  # Split the base name to get the name without the extension\n",
    "    \n",
    "    try: # Remove image frames path if it already exists\n",
    "        os.remove(f\"{vidname}_image_frames\")\n",
    "    except OSError:\n",
    "        pass\n",
    "    if not os.path.exists(f\"{vidname}_image_frames\"): # create the directory if it does not already exist\n",
    "        os.makedirs(f\"{vidname}_image_frames\")\n",
    "\n",
    "    src_vid = cv2.VideoCapture(vidpath) # open the video file\n",
    "    return(src_vid)\n",
    "    \n",
    "def process(src_vid, frame_interval):\n",
    "    base_name = os.path.basename(vidpath)\n",
    "    vidname, _ = os.path.splitext(base_name)  # Split the base name to get the name without the extension\n",
    "    saved_frame_nums = []\n",
    "    \n",
    "    index = 0\n",
    "    while src_vid.isOpened():\n",
    "        ret, frame = src_vid.read() \n",
    "        if not ret: # break at the end of the video (ret returns True if frame is succesfully read)\n",
    "            break\n",
    "        name = f'./{vidname}_image_frames/frame{str(index)}.png'\n",
    "\n",
    "        if index % frame_interval == 0: # every 50th frame will be saved: can adjust this number to capture more or less frames\n",
    "            print('Extracting frame...' + name)\n",
    "            cv2.imwrite(name, frame)\n",
    "            saved_frame_nums.append(index)\n",
    "        index = index + 1\n",
    "        \n",
    "    src_vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    video_frames_dir = f\"./{vidname}_image_frames\"\n",
    "    \n",
    "    return saved_frame_nums, video_frames_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frame..../train4_crop_image_frames/frame0.png\n",
      "Extracting frame..../train4_crop_image_frames/frame25.png\n",
      "Extracting frame..../train4_crop_image_frames/frame50.png\n",
      "Extracting frame..../train4_crop_image_frames/frame75.png\n",
      "Extracting frame..../train4_crop_image_frames/frame100.png\n",
      "Extracting frame..../train4_crop_image_frames/frame125.png\n",
      "Extracting frame..../train4_crop_image_frames/frame150.png\n",
      "Extracting frame..../train4_crop_image_frames/frame175.png\n",
      "Extracting frame..../train4_crop_image_frames/frame200.png\n",
      "Extracting frame..../train4_crop_image_frames/frame225.png\n",
      "Extracting frame..../train4_crop_image_frames/frame250.png\n",
      "Extracting frame..../train4_crop_image_frames/frame275.png\n",
      "Extracting frame..../train4_crop_image_frames/frame300.png\n",
      "Extracting frame..../train4_crop_image_frames/frame325.png\n",
      "Extracting frame..../train4_crop_image_frames/frame350.png\n",
      "Extracting frame..../train4_crop_image_frames/frame375.png\n",
      "Extracting frame..../train4_crop_image_frames/frame400.png\n",
      "Extracting frame..../train4_crop_image_frames/frame425.png\n"
     ]
    }
   ],
   "source": [
    "vid = files(vidpath)\n",
    "saved_frame_nums, video_frames_dir = process(vid, frame_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_horizontal_flow(img, flow, step=30):\n",
    "    \"\"\"Draw optical flow vectors on the video.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    y, x = np.mgrid[step//2:h:step, step//2:w:step].reshape(2, -1).astype(int)\n",
    "    fx = flow[y, x, 0]\n",
    "    fy = flow[y, x, 1]\n",
    "\n",
    "    # Keep only leftward motion vectors (negative horizontal flow)\n",
    "    fx[fx > 0] = 0\n",
    "\n",
    "    lines = np.vstack([x, y, x + fx, y + fy]).T.reshape(-1, 2, 2)\n",
    "    lines = np.int32(lines + 0.5)\n",
    "\n",
    "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    for (x1, y1), (x2, y2) in lines:\n",
    "        cv2.arrowedLine(vis, (x1, y1), (x2, y2), (0, 255, 0), 1, tipLength=0.5)\n",
    "    return vis\n",
    "\n",
    "def detect_and_save_screengrab(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get total number of frames and calculate halfway point\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    halfway_frame = total_frames // 2\n",
    "\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read the video file.\")\n",
    "        return\n",
    "\n",
    "    prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize a mask for consistent leftward movement\n",
    "    consistent_motion_mask = None\n",
    "    consistency_threshold = 0.8  # Consistent movement threshold (percentage of frames)\n",
    "    num_frames = 0\n",
    "\n",
    "    saved_screengrab = False\n",
    "    screengrab_frame = None\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 5, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Calculate the mask of leftward movement\n",
    "        leftward_motion_mask = flow[..., 0] < 0\n",
    "        \n",
    "        # Initialize the consistent motion mask\n",
    "        if consistent_motion_mask is None:\n",
    "            consistent_motion_mask = np.zeros_like(leftward_motion_mask, dtype=np.float32)\n",
    "        \n",
    "        # Update the consistent leftward movement mask\n",
    "        consistent_motion_mask[leftward_motion_mask] += 1\n",
    "        num_frames += 1\n",
    "\n",
    "        # Calculate the ratio of consistent leftward movement\n",
    "        consistent_ratio = consistent_motion_mask / num_frames\n",
    "        consistent_leftward_regions = consistent_ratio > consistency_threshold\n",
    "\n",
    "        # Apply morphological operations to fill in the gaps\n",
    "        consistent_leftward_mask = consistent_leftward_regions.astype(np.uint8)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        consistent_leftward_mask = cv2.morphologyEx(consistent_leftward_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "        # Create an image for highlighting\n",
    "        consistent_leftward_img = np.zeros_like(frame)\n",
    "        consistent_leftward_img[consistent_leftward_mask == 1] = [0, 255, 0]  # Green\n",
    "\n",
    "        vis = draw_horizontal_flow(gray, flow)\n",
    "\n",
    "        # Combine visualization with consistent leftward movement highlight\n",
    "        combined_vis = cv2.addWeighted(vis, 0.7, consistent_leftward_img, 0.3, 0)\n",
    "\n",
    "        # Save screengrab at halfway point\n",
    "        if num_frames == halfway_frame and not saved_screengrab:\n",
    "            screengrab_frame = combined_vis.copy()\n",
    "            saved_screengrab = True\n",
    "        \n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    # Save the screengrab outside the loop to avoid delay\n",
    "    if screengrab_frame is not None:\n",
    "        vidname = str(video_path)\n",
    "        cv2.imwrite(f'{vidname}_screengrab_halfway.png', screengrab_frame)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## CALL TO FUNCTION:\n",
    "detect_and_save_screengrab(vidpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Draw a bounding box around the detected regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bounding_boxes(vidpath, height_increase=0, opflow_min_area_threshold=700):\n",
    "    opflow_box_coordinates = []\n",
    "    screengrab_path = f'{vidpath}_screengrab_halfway.png'\n",
    "    \n",
    "    screengrab = cv2.imread(screengrab_path)\n",
    "    if screengrab is None:\n",
    "        print(\"Failed to read the screengrab.\")\n",
    "        return\n",
    "\n",
    "    # Convert to HSV and create a mask for the green color\n",
    "    hsv = cv2.cvtColor(screengrab, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([40, 40, 40])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around significant motion regions\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > opflow_min_area_threshold:  # Adjust the threshold for minimum area as needed\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Increase the height of the bounding box\n",
    "            y = max(0, y - height_increase // 2)\n",
    "            h = h + height_increase\n",
    "            # Ensure the bounding box is within the image boundaries\n",
    "            h = min(h, screengrab.shape[0] - y)\n",
    "            cv2.rectangle(screengrab, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            opflow_box_coordinates += [[x, y, x+w, y+h]]\n",
    "\n",
    "    # Save and display the image with bounding boxes\n",
    "    cv2.imwrite(f'{vidpath}_screengrab_with_bounding_boxes.png', screengrab)\n",
    "    \n",
    "    return opflow_box_coordinates\n",
    "\n",
    "########## CALL TO FUNCTION:\n",
    "opflow_box_coordinates = extract_bounding_boxes(vidpath, opflow_height_increase, opflow_min_area_threshold) # Add extra height to ensure no text is cut off from the top/bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EAST for text detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def east_detect(image, output_path, east_confidence):\n",
    "    ''' uses EAST detection to get x,y coordinates of all bounding boxes of input image \n",
    "    \n",
    "    param images: paths to the image\n",
    "    param output_path: path where to save copy of original image with bounding boxes drawn on top\n",
    "    \n",
    "    returns list of tuples: each tuple contains (x_min, y_min, x_max, y_max) of each detected bounding box\n",
    "\n",
    "    code from: https://medium.com/technovators/scene-text-detection-in-python-with-east-and-craft-cbe03dda35d5\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    layerNames = [\n",
    "    \t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "    \t\"feature_fusion/concat_3\"]\n",
    "    \n",
    "    orig = image.copy()\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    # for both the width and height: Should be multiple of 32\n",
    "    (newW, newH) = (672, 672)\n",
    "    \n",
    "    rW = W / float(newW)\n",
    "    rH = H / float(newH)\n",
    "    \n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, newH))\n",
    "    \n",
    "    (H, W) = image.shape[:2]\n",
    "    \n",
    "    net = cv2.dnn.readNet(\"frozen_east_text_detection.pb\")\n",
    "    \n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "    \t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    \n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "    \n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the geometrical\n",
    "        # data used to derive potential bounding box coordinates that\n",
    "        # surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "    \n",
    "        for x in range(0, numCols):\n",
    "    \t\t# if our score does not have sufficient probability, ignore it\n",
    "            # Set minimum confidence as required\n",
    "            if scoresData[x] < east_confidence:\n",
    "                continue\n",
    "    \t\t# compute the offset factor as our resulting feature maps will\n",
    "            #  x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "            # extract the rotation angle for the prediction and then\n",
    "            # compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "            # use the geometry volume to derive the width and height of\n",
    "            # the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "            # compute both the starting and ending (x, y)-coordinates for\n",
    "            # the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "            # add the bounding box coordinates and probability score to\n",
    "            # our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "                        \n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "    # loop over the bounding boxes\n",
    "    coordinates = []\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        # scale the bounding box coordinates based on the respective\n",
    "        # ratios\n",
    "        startX = int(startX * rW)\n",
    "        startY = int(startY * rH)\n",
    "        endX = int(endX * rW)\n",
    "        endY = int(endY * rH)\n",
    "        # draw the bounding box on the image\n",
    "        # startX,startY ------\n",
    "        # |                 |\n",
    "        # |                 |\n",
    "        # |                 |\n",
    "        # ----------endX,endY\n",
    "        out_image = cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        # out_image = cv2.rectangle(out_image, (146, 888), (1920, 1002), (0, 255, 0), 2)\n",
    "        coordinates += [[startX, startY, endX, endY]]\n",
    "    \n",
    "    cv2.imwrite(f\"{output_path}\", out_image)\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_list= []\n",
    "\n",
    "for frame_number in saved_frame_nums:\n",
    "\tframe_path = video_frames_dir + f\"/frame{frame_number}.png\" # path to individual frame being processed\n",
    "\n",
    "\tbase_name = os.path.basename(frame_path)\n",
    "\tframe_name, _ = os.path.splitext(base_name) # get just the individual frame name without the extension\n",
    "\n",
    "\tif not os.path.isdir(f\"{video_frames_dir}/output\"):\n",
    "\t\tos.makedirs(f\"{video_frames_dir}/output\") # makes output directory for the frame being processed\n",
    "\t\n",
    "\timage = cv2.imread(frame_path) \n",
    "\tcoordinates = east_detect(image, f\"{video_frames_dir}/output/out_{frame_name}_EAST.png\", east_confidence) # get coordinates of bounding boxes and save image to new output dir for that frame\n",
    "\n",
    "\tcoordinates_list += [coordinates]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the overlapping area of optic flow rectangles and east rectangles.\n",
    "\n",
    "randomly get {N} frames to do this:\n",
    "* For each opflow rectangle, get the overlapping area sum \n",
    "* The rectangle with the largest overlapping area -> rolling text region \\\n",
    "-> some sanity check for rectangles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1877, 754, 1920, 791], [696, 549, 1157, 592]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opflow_box_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[820, 596, 1014, 630],\n",
       "  [865, 718, 1077, 748],\n",
       "  [1034, 589, 1102, 626],\n",
       "  [548, 691, 637, 721],\n",
       "  [942, 567, 1040, 586],\n",
       "  [868, 683, 1011, 711],\n",
       "  [537, 728, 620, 761],\n",
       "  [717, 604, 797, 634],\n",
       "  [697, 728, 765, 756],\n",
       "  [1011, 679, 1085, 708],\n",
       "  [557, 662, 654, 683],\n",
       "  [725, 689, 820, 716],\n",
       "  [611, 557, 682, 583],\n",
       "  [1014, 564, 1085, 591],\n",
       "  [837, 567, 968, 593],\n",
       "  [565, 586, 645, 609],\n",
       "  [725, 572, 820, 591],\n",
       "  [1588, 898, 1660, 919],\n",
       "  [1837, 585, 1900, 613],\n",
       "  [754, 546, 860, 565]],\n",
       " [[814, 589, 1017, 625],\n",
       "  [845, 713, 1057, 745],\n",
       "  [848, 676, 988, 708],\n",
       "  [1017, 583, 1094, 620],\n",
       "  [531, 686, 622, 716],\n",
       "  [805, 564, 945, 586],\n",
       "  [697, 599, 777, 628],\n",
       "  [531, 655, 640, 676],\n",
       "  [954, 560, 1031, 583],\n",
       "  [1105, 531, 1177, 552],\n",
       "  [520, 723, 602, 761],\n",
       "  [731, 565, 828, 586],\n",
       "  [1011, 673, 1074, 705],\n",
       "  [682, 721, 760, 752],\n",
       "  [737, 681, 808, 711],\n",
       "  [548, 581, 617, 604],\n",
       "  [1034, 535, 1114, 552],\n",
       "  [917, 98, 980, 120],\n",
       "  [714, 541, 828, 560],\n",
       "  [608, 554, 668, 576],\n",
       "  [1645, 564, 1760, 647],\n",
       "  [682, 683, 740, 711]],\n",
       " [[840, 684, 980, 716],\n",
       "  [1002, 594, 1074, 628],\n",
       "  [785, 596, 1005, 631],\n",
       "  [688, 605, 768, 634],\n",
       "  [977, 684, 1054, 713],\n",
       "  [840, 724, 1045, 753],\n",
       "  [500, 732, 594, 765],\n",
       "  [700, 692, 788, 720],\n",
       "  [557, 559, 657, 585],\n",
       "  [517, 662, 625, 683],\n",
       "  [674, 732, 737, 760],\n",
       "  [540, 588, 625, 610],\n",
       "  [708, 573, 831, 593],\n",
       "  [520, 695, 611, 723],\n",
       "  [925, 568, 1008, 591],\n",
       "  [1074, 541, 1168, 562],\n",
       "  [991, 543, 1077, 562],\n",
       "  [905, 107, 980, 133],\n",
       "  [831, 570, 934, 589],\n",
       "  [197, 242, 337, 414],\n",
       "  [728, 548, 857, 570]],\n",
       " [[771, 604, 988, 644],\n",
       "  [837, 694, 971, 723],\n",
       "  [825, 734, 1034, 761],\n",
       "  [917, 580, 1002, 599],\n",
       "  [488, 742, 585, 773],\n",
       "  [668, 699, 780, 726],\n",
       "  [1002, 602, 1074, 639],\n",
       "  [982, 691, 1054, 723],\n",
       "  [505, 700, 597, 729],\n",
       "  [668, 613, 771, 644],\n",
       "  [1042, 548, 1165, 570],\n",
       "  [511, 670, 617, 689],\n",
       "  [651, 739, 745, 766],\n",
       "  [994, 578, 1054, 601],\n",
       "  [800, 580, 925, 601],\n",
       "  [528, 591, 602, 617],\n",
       "  [708, 556, 831, 578],\n",
       "  [585, 567, 648, 594],\n",
       "  [917, 115, 977, 138]],\n",
       " [[825, 734, 1037, 765],\n",
       "  [831, 697, 965, 726],\n",
       "  [780, 602, 991, 646],\n",
       "  [974, 694, 1048, 726],\n",
       "  [488, 742, 585, 773],\n",
       "  [1000, 604, 1068, 641],\n",
       "  [662, 700, 774, 726],\n",
       "  [800, 581, 922, 609],\n",
       "  [660, 613, 774, 647],\n",
       "  [511, 702, 591, 729],\n",
       "  [1017, 554, 1134, 573],\n",
       "  [931, 557, 1008, 575],\n",
       "  [194, 253, 342, 403],\n",
       "  [648, 739, 745, 766],\n",
       "  [925, 580, 1011, 604],\n",
       "  [505, 673, 605, 691],\n",
       "  [1637, 581, 1725, 678],\n",
       "  [171, 985, 254, 1018],\n",
       "  [845, 559, 922, 580]],\n",
       " [[828, 695, 977, 726],\n",
       "  [825, 740, 1042, 768],\n",
       "  [780, 609, 980, 650],\n",
       "  [980, 695, 1054, 728],\n",
       "  [514, 703, 588, 734],\n",
       "  [494, 742, 580, 774],\n",
       "  [665, 615, 771, 649],\n",
       "  [1000, 605, 1080, 644],\n",
       "  [662, 700, 768, 731],\n",
       "  [505, 673, 602, 695],\n",
       "  [994, 559, 1097, 578],\n",
       "  [182, 257, 325, 421],\n",
       "  [542, 572, 625, 601],\n",
       "  [911, 583, 997, 607],\n",
       "  [525, 594, 614, 621],\n",
       "  [982, 580, 1057, 604],\n",
       "  [771, 583, 942, 607],\n",
       "  [654, 740, 768, 771],\n",
       "  [1640, 588, 1722, 681]],\n",
       " [[780, 609, 982, 649],\n",
       "  [825, 739, 1045, 769],\n",
       "  [677, 621, 765, 650],\n",
       "  [825, 700, 968, 729],\n",
       "  [1000, 607, 1074, 647],\n",
       "  [671, 703, 777, 734],\n",
       "  [985, 697, 1057, 728],\n",
       "  [485, 747, 585, 777],\n",
       "  [505, 678, 605, 697],\n",
       "  [920, 586, 1008, 610],\n",
       "  [525, 599, 611, 621],\n",
       "  [197, 261, 342, 411],\n",
       "  [508, 707, 591, 736],\n",
       "  [797, 585, 920, 609],\n",
       "  [962, 560, 1060, 580],\n",
       "  [1645, 594, 1725, 691],\n",
       "  [642, 744, 765, 773],\n",
       "  [1082, 557, 1157, 578],\n",
       "  [697, 588, 791, 609]],\n",
       " [[797, 613, 982, 654],\n",
       "  [831, 703, 971, 732],\n",
       "  [845, 740, 1045, 771],\n",
       "  [534, 604, 602, 625],\n",
       "  [497, 745, 585, 777],\n",
       "  [985, 700, 1051, 732],\n",
       "  [511, 678, 620, 697],\n",
       "  [1008, 609, 1077, 649],\n",
       "  [668, 621, 765, 654],\n",
       "  [802, 585, 940, 610],\n",
       "  [662, 744, 734, 774],\n",
       "  [954, 586, 1060, 609],\n",
       "  [514, 707, 594, 736],\n",
       "  [834, 557, 957, 585],\n",
       "  [711, 708, 777, 737],\n",
       "  [191, 266, 334, 416],\n",
       "  [545, 575, 611, 599],\n",
       "  [928, 559, 1045, 583],\n",
       "  [722, 337, 828, 358],\n",
       "  [1642, 605, 1737, 689],\n",
       "  [705, 588, 805, 609]],\n",
       " [[782, 609, 991, 646],\n",
       "  [840, 740, 1042, 769],\n",
       "  [828, 700, 977, 729],\n",
       "  [677, 620, 765, 650],\n",
       "  [500, 747, 588, 776],\n",
       "  [1002, 605, 1082, 646],\n",
       "  [985, 697, 1057, 729],\n",
       "  [531, 602, 617, 623],\n",
       "  [928, 585, 1045, 607],\n",
       "  [665, 744, 731, 774],\n",
       "  [722, 703, 777, 736],\n",
       "  [508, 678, 628, 697],\n",
       "  [554, 572, 657, 599],\n",
       "  [797, 585, 931, 609],\n",
       "  [197, 266, 340, 414],\n",
       "  [1042, 559, 1125, 580]],\n",
       " [[825, 734, 1048, 766],\n",
       "  [834, 697, 974, 726],\n",
       "  [782, 607, 988, 647],\n",
       "  [1005, 604, 1080, 639],\n",
       "  [522, 703, 594, 734],\n",
       "  [980, 695, 1057, 728],\n",
       "  [500, 742, 585, 774],\n",
       "  [665, 739, 734, 773],\n",
       "  [725, 699, 780, 734],\n",
       "  [871, 559, 988, 578],\n",
       "  [671, 615, 777, 649],\n",
       "  [974, 581, 1060, 602],\n",
       "  [531, 596, 614, 620],\n",
       "  [794, 580, 948, 604],\n",
       "  [520, 673, 622, 691],\n",
       "  [188, 255, 337, 429],\n",
       "  [788, 557, 877, 576],\n",
       "  [1017, 557, 1108, 576]],\n",
       " [[777, 601, 1002, 636],\n",
       "  [837, 689, 968, 720],\n",
       "  [525, 591, 605, 615],\n",
       "  [834, 728, 1037, 758],\n",
       "  [997, 601, 1065, 633],\n",
       "  [974, 686, 1040, 720],\n",
       "  [668, 610, 762, 638],\n",
       "  [494, 734, 591, 765],\n",
       "  [788, 573, 934, 594],\n",
       "  [674, 694, 782, 721],\n",
       "  [928, 575, 1005, 594],\n",
       "  [514, 665, 605, 684],\n",
       "  [997, 549, 1065, 572],\n",
       "  [508, 695, 594, 723],\n",
       "  [188, 241, 320, 425],\n",
       "  [1640, 576, 1725, 673],\n",
       "  [717, 575, 814, 596],\n",
       "  [1057, 548, 1154, 568]],\n",
       " [[820, 721, 1025, 752],\n",
       "  [780, 597, 980, 630],\n",
       "  [820, 686, 962, 715],\n",
       "  [997, 591, 1062, 625],\n",
       "  [965, 683, 1037, 713],\n",
       "  [491, 724, 574, 760],\n",
       "  [660, 687, 774, 715],\n",
       "  [668, 604, 751, 633],\n",
       "  [917, 570, 1017, 589],\n",
       "  [502, 658, 608, 678],\n",
       "  [522, 585, 591, 609],\n",
       "  [648, 726, 725, 756],\n",
       "  [500, 687, 585, 718],\n",
       "  [1040, 540, 1154, 560],\n",
       "  [791, 568, 920, 593],\n",
       "  [408, 906, 731, 967],\n",
       "  [711, 544, 820, 565],\n",
       "  [680, 570, 782, 593],\n",
       "  [825, 544, 928, 565],\n",
       "  [1634, 554, 1720, 666]],\n",
       " [[825, 721, 1031, 750],\n",
       "  [777, 593, 994, 626],\n",
       "  [997, 589, 1065, 625],\n",
       "  [494, 726, 580, 760],\n",
       "  [822, 683, 965, 711],\n",
       "  [965, 681, 1037, 711],\n",
       "  [674, 602, 757, 631],\n",
       "  [911, 568, 1011, 588],\n",
       "  [717, 572, 808, 593],\n",
       "  [494, 687, 591, 720],\n",
       "  [671, 687, 774, 715],\n",
       "  [791, 565, 928, 591],\n",
       "  [497, 658, 620, 679],\n",
       "  [422, 906, 714, 967],\n",
       "  [531, 580, 591, 605],\n",
       "  [654, 724, 740, 753],\n",
       "  [51, 891, 154, 922],\n",
       "  [714, 546, 794, 565],\n",
       "  [991, 538, 1117, 560],\n",
       "  [1645, 557, 1728, 670],\n",
       "  [185, 244, 354, 401]],\n",
       " [[828, 720, 1031, 748],\n",
       "  [777, 594, 1002, 630],\n",
       "  [1002, 588, 1071, 626],\n",
       "  [828, 683, 971, 711],\n",
       "  [491, 726, 582, 761],\n",
       "  [502, 687, 594, 720],\n",
       "  [794, 568, 928, 593],\n",
       "  [980, 681, 1051, 708],\n",
       "  [908, 568, 1005, 588],\n",
       "  [680, 602, 768, 631],\n",
       "  [668, 687, 780, 716],\n",
       "  [525, 583, 602, 607],\n",
       "  [508, 657, 614, 678],\n",
       "  [197, 242, 340, 408],\n",
       "  [762, 543, 877, 562],\n",
       "  [422, 906, 722, 969],\n",
       "  [991, 564, 1054, 588],\n",
       "  [660, 724, 734, 755]],\n",
       " [[802, 593, 988, 626],\n",
       "  [834, 713, 1042, 745],\n",
       "  [834, 676, 974, 708],\n",
       "  [1000, 585, 1074, 621],\n",
       "  [500, 721, 591, 753],\n",
       "  [985, 676, 1054, 708],\n",
       "  [534, 578, 605, 601],\n",
       "  [922, 564, 1017, 586],\n",
       "  [785, 564, 928, 586],\n",
       "  [662, 720, 731, 752],\n",
       "  [680, 597, 765, 626],\n",
       "  [511, 654, 620, 673],\n",
       "  [191, 242, 348, 388],\n",
       "  [548, 548, 631, 575],\n",
       "  [722, 681, 782, 710],\n",
       "  [525, 683, 597, 711],\n",
       "  [668, 683, 722, 710],\n",
       "  [54, 880, 185, 916]],\n",
       " [[797, 580, 988, 618],\n",
       "  [837, 668, 982, 699],\n",
       "  [937, 552, 1028, 573],\n",
       "  [1002, 576, 1077, 613],\n",
       "  [828, 707, 1034, 734],\n",
       "  [497, 710, 597, 742],\n",
       "  [985, 668, 1060, 697],\n",
       "  [514, 641, 617, 660],\n",
       "  [700, 673, 785, 699],\n",
       "  [511, 671, 605, 700],\n",
       "  [662, 710, 737, 739],\n",
       "  [682, 586, 774, 617],\n",
       "  [800, 556, 928, 576],\n",
       "  [542, 567, 611, 589],\n",
       "  [557, 541, 605, 567],\n",
       "  [720, 554, 831, 575],\n",
       "  [740, 711, 785, 739]],\n",
       " [[808, 567, 991, 604],\n",
       "  [842, 695, 1042, 723],\n",
       "  [922, 541, 1017, 562],\n",
       "  [1005, 564, 1077, 602],\n",
       "  [497, 697, 591, 726],\n",
       "  [808, 540, 931, 562],\n",
       "  [988, 652, 1060, 683],\n",
       "  [828, 657, 977, 684],\n",
       "  [665, 692, 737, 724],\n",
       "  [682, 573, 774, 604],\n",
       "  [514, 626, 631, 646],\n",
       "  [542, 552, 605, 575],\n",
       "  [197, 210, 354, 356],\n",
       "  [714, 543, 817, 562],\n",
       "  [722, 657, 780, 689],\n",
       "  [45, 856, 180, 893],\n",
       "  [554, 527, 605, 552]],\n",
       " [[794, 557, 994, 599],\n",
       "  [834, 646, 982, 675],\n",
       "  [985, 646, 1062, 676],\n",
       "  [828, 687, 1045, 716],\n",
       "  [520, 652, 597, 683],\n",
       "  [497, 691, 591, 723],\n",
       "  [1000, 554, 1080, 594],\n",
       "  [682, 565, 780, 597],\n",
       "  [665, 687, 728, 721],\n",
       "  [934, 533, 1028, 556],\n",
       "  [1031, 509, 1117, 528],\n",
       "  [540, 546, 622, 568],\n",
       "  [731, 650, 782, 687],\n",
       "  [517, 621, 622, 639],\n",
       "  [791, 531, 945, 557],\n",
       "  [694, 536, 794, 556],\n",
       "  [551, 519, 625, 544]]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap_area(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Calculate the overlapping area between two rectangles.\n",
    "    \n",
    "    rect1 and rect2 are tuples in the form (startX, startY, endX, endY)\n",
    "    \"\"\"\n",
    "    x1_max = max(rect1[0], rect2[0])\n",
    "    y1_max = max(rect1[1], rect2[1])\n",
    "    x2_min = min(rect1[2], rect2[2])\n",
    "    y2_min = min(rect1[3], rect2[3])\n",
    "    \n",
    "    overlap_width = max(0, x2_min - x1_max)\n",
    "    overlap_height = max(0, y2_min - y1_max)\n",
    "    \n",
    "    if x1_max >= x2_min or y1_max >= y2_min:\n",
    "        return 0\n",
    "    \n",
    "    return overlap_width * overlap_height\n",
    "\n",
    "\n",
    "def sum_overlapping_areas(main_rect, rectangles):\n",
    "    \"\"\"\n",
    "    Calculate the sum of overlapping areas of multiple rectangles with the main rectangle.\n",
    "    \n",
    "    main_rect is a tuple in the form (startX, startY, endX, endY)\n",
    "    rectangles is a list of tuples in the same form\n",
    "    \"\"\"\n",
    "    total_overlap_area = 0\n",
    "    for rect in rectangles:\n",
    "        total_overlap_area += calculate_overlap_area(main_rect, rect)\n",
    "    \n",
    "    return total_overlap_area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlap_areas = []\n",
    "choose_frames = random.sample(list(range(len(saved_frame_nums))), num_frames_for_overlap_check)\n",
    "\n",
    "for opflow_box_coordinate in opflow_box_coordinates:\n",
    "    total_overlap = 0\n",
    "    for frame_index in choose_frames:\n",
    "        total_overlap += sum_overlapping_areas(opflow_box_coordinate, coordinates_list[frame_index])\n",
    "    overlap_areas.append(total_overlap)\n",
    "\n",
    "rolling_box_index = np.argmax(np.array(overlap_areas))\n",
    "rolling_box = opflow_box_coordinates[rolling_box_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After getting the rolling box\n",
    "\n",
    "* For all the east boxes in each frame, calculate their overlapping area with the rolling box\n",
    "* If overlapping area / east box area >= rolling_text_confidence, this is a part of the rolling text\n",
    "* Crop this part and save to the folder in each frame. \\\n",
    "TBD: The cropped text images should follow a left to right sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: The cropped text images should follow a left to right sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save_image(image_path, coords, output_path):\n",
    "    ''' saves crops of original image according to specified coordinates \n",
    "\n",
    "    param image_path: path to original image\n",
    "    param coordinates: coordinates of bounding boxes in tuple (x_min, y_min, x_max, y_max)\n",
    "    param output_path: path of output file'''\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    x_min, y_min, x_max, y_max = coords\n",
    "    cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Save\n",
    "    cv2.imwrite(output_path, cropped_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame0/4.jpg for rectangle [942, 567, 1040, 586]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame0/13.jpg for rectangle [1014, 564, 1085, 591]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame0/14.jpg for rectangle [837, 567, 968, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame0/16.jpg for rectangle [725, 572, 820, 591]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame0/19.jpg for rectangle [754, 546, 860, 565]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame25/5.jpg for rectangle [805, 564, 945, 586]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame25/8.jpg for rectangle [954, 560, 1031, 583]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame25/11.jpg for rectangle [731, 565, 828, 586]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame25/18.jpg for rectangle [714, 541, 828, 560]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/12.jpg for rectangle [708, 573, 831, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/14.jpg for rectangle [925, 568, 1008, 591]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/15.jpg for rectangle [1074, 541, 1168, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/16.jpg for rectangle [991, 543, 1077, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/18.jpg for rectangle [831, 570, 934, 589]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame50/20.jpg for rectangle [728, 548, 857, 570]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame75/3.jpg for rectangle [917, 580, 1002, 599]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame75/10.jpg for rectangle [1042, 548, 1165, 570]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame75/13.jpg for rectangle [994, 578, 1054, 601]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame75/14.jpg for rectangle [800, 580, 925, 601]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame75/16.jpg for rectangle [708, 556, 831, 578]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame100/10.jpg for rectangle [1017, 554, 1134, 573]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame100/11.jpg for rectangle [931, 557, 1008, 575]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame100/14.jpg for rectangle [925, 580, 1011, 604]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame100/18.jpg for rectangle [845, 559, 922, 580]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame125/10.jpg for rectangle [994, 559, 1097, 578]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame125/15.jpg for rectangle [982, 580, 1057, 604]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame150/14.jpg for rectangle [962, 560, 1060, 580]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame150/17.jpg for rectangle [1082, 557, 1157, 578]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame175/13.jpg for rectangle [834, 557, 957, 585]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame175/17.jpg for rectangle [928, 559, 1045, 583]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame200/15.jpg for rectangle [1042, 559, 1125, 580]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame225/9.jpg for rectangle [871, 559, 988, 578]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame225/11.jpg for rectangle [974, 581, 1060, 602]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame225/13.jpg for rectangle [794, 580, 948, 604]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame225/16.jpg for rectangle [788, 557, 877, 576]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame225/17.jpg for rectangle [1017, 557, 1108, 576]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame250/8.jpg for rectangle [788, 573, 934, 594]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame250/10.jpg for rectangle [928, 575, 1005, 594]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame250/12.jpg for rectangle [997, 549, 1065, 572]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame250/16.jpg for rectangle [717, 575, 814, 596]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame250/17.jpg for rectangle [1057, 548, 1154, 568]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/8.jpg for rectangle [917, 570, 1017, 589]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/13.jpg for rectangle [1040, 540, 1154, 560]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/14.jpg for rectangle [791, 568, 920, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/16.jpg for rectangle [711, 544, 820, 565]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/17.jpg for rectangle [680, 570, 782, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame275/18.jpg for rectangle [825, 544, 928, 565]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame300/7.jpg for rectangle [911, 568, 1011, 588]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame300/8.jpg for rectangle [717, 572, 808, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame300/11.jpg for rectangle [791, 565, 928, 591]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame300/17.jpg for rectangle [714, 546, 794, 565]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame300/18.jpg for rectangle [991, 538, 1117, 560]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame325/6.jpg for rectangle [794, 568, 928, 593]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame325/8.jpg for rectangle [908, 568, 1005, 588]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame325/14.jpg for rectangle [762, 543, 877, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame325/16.jpg for rectangle [991, 564, 1054, 588]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame350/7.jpg for rectangle [922, 564, 1017, 586]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame350/8.jpg for rectangle [785, 564, 928, 586]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame375/2.jpg for rectangle [937, 552, 1028, 573]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame375/12.jpg for rectangle [800, 556, 928, 576]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame375/15.jpg for rectangle [720, 554, 831, 575]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/0.jpg for rectangle [808, 567, 991, 604]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/2.jpg for rectangle [922, 541, 1017, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/3.jpg for rectangle [1005, 564, 1077, 602]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/5.jpg for rectangle [808, 540, 931, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/9.jpg for rectangle [682, 573, 774, 604]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame400/13.jpg for rectangle [714, 543, 817, 562]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame425/0.jpg for rectangle [794, 557, 994, 599]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame425/6.jpg for rectangle [1000, 554, 1080, 594]\n",
      "Saved cropped image to ./train4_crop_image_frames/croppedFrame425/7.jpg for rectangle [682, 565, 780, 597]\n"
     ]
    }
   ],
   "source": [
    "for frame_num, rects in zip(saved_frame_nums, coordinates_list):\n",
    "    frame_path = f\"{video_frames_dir}/frame{frame_num}.png\"\n",
    "    output_path = f\"{video_frames_dir}/croppedFrame{frame_num}\"\n",
    "    if os.path.isdir(output_path):\n",
    "        print(\"The cropped folders are there! You can delete them :)\")\n",
    "        continue\n",
    "    else:\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    for idx, rect in enumerate(rects):\n",
    "        overlap_area = calculate_overlap_area(rolling_box, rect)\n",
    "        rect_area = (rect[2] - rect[0]) * (rect[3] - rect[1])\n",
    "        if rect_area > 0 and (overlap_area / rect_area) >= rolling_text_confidence:\n",
    "            final_outout_path = f\"{output_path}/{idx}.jpg\"\n",
    "            crop_and_save_image(frame_path, rect, final_outout_path)\n",
    "            print(f\"Saved cropped image to {final_outout_path} for rectangle {rect}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
